<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>https://qi.tc/</id><title>Qi Stream</title><updated>2024-07-16T08:16:09.419503+00:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><link href="https://qi.tc" rel="alternate" type="text/html"/><link href="https://structured-query-language.github.io/feed.xml" rel="self" type="application/atom+xml"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><subtitle>Qi Stream</subtitle><entry><id>https://qi.tc/qi/120672</id><title>( PDF) #NeuralNetwork and Its Learning Techniques | Admin ASDF - Academia .edu</title><updated>2024-07-15T19:15:54.168671+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) #NeuralNetwork and Its Learning Techniques | Admin ASDF - Academia .edu</content><link href="https://qi.tc/qi/120672" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.168671+02:00</published></entry><entry><id>https://qi.tc/qi/120671</id><title>( PDF) Self-Recurrent #NeuralNetwork | massimo buscema - Academia .edu</title><updated>2024-07-15T19:15:54.222225+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) Self-Recurrent #NeuralNetwork | massimo buscema - Academia .edu</content><link href="https://qi.tc/qi/120671" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.222225+02:00</published></entry><entry><id>https://qi.tc/qi/120669</id><title>( PDF) IRJET - Basic Overview of #NeuralNetwork , Stochastic Gradient Descent and Activation Function | IRJET Journal - Academia .edu</title><updated>2024-07-15T19:15:54.331189+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) IRJET - Basic Overview of #NeuralNetwork , Stochastic Gradient Descent and Activation Function | IRJET Journal - Academia .edu</content><link href="https://qi.tc/qi/120669" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.331189+02:00</published></entry><entry><id>https://qi.tc/qi/120668</id><title>( PDF) A comparison of the backpropagation and recursive prediction error algorithms for training #NeuralNetwork | Hishamuddin Jamaluddin - Academia .edu</title><updated>2024-07-15T19:15:54.444039+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) A comparison of the backpropagation and recursive prediction error algorithms for training #NeuralNetwork | Hishamuddin Jamaluddin - Academia .edu</content><link href="https://qi.tc/qi/120668" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.444039+02:00</published></entry><entry><id>https://qi.tc/qi/120667</id><title>( PDF) Neural Ordinary Differential Equation based Recurrent #NeuralNetwork Model | Mansura Habiba - Academia .edu</title><updated>2024-07-15T19:15:54.557515+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) Neural Ordinary Differential Equation based Recurrent #NeuralNetwork Model | Mansura Habiba - Academia .edu</content><link href="https://qi.tc/qi/120667" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.557515+02:00</published></entry><entry><id>https://qi.tc/qi/120666</id><title>( PDF) A general backpropagation algorithm for feedforward #NeuralNetwork learning | Mehmet Onder Efe - Academia .edu</title><updated>2024-07-15T19:15:54.663880+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) A general backpropagation algorithm for feedforward #NeuralNetwork learning | Mehmet Onder Efe - Academia .edu</content><link href="https://qi.tc/qi/120666" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.663880+02:00</published></entry><entry><id>https://qi.tc/qi/120665</id><title>( PDF) Emergence of Prediction by #ReinforcementLearning Using a Recurrent #NeuralNetwork | Katsunari Shibata - Academia .edu</title><updated>2024-07-15T19:15:54.829514+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) Emergence of Prediction by #ReinforcementLearning Using a Recurrent #NeuralNetwork | Katsunari Shibata - Academia .edu</content><link href="https://qi.tc/qi/120665" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.829514+02:00</published></entry><entry><id>https://qi.tc/qi/120664</id><title>( PDF) Recurrent #NeuralNetwork for signal processing trained by a new second order algorithm | Aurelio Uncini - Academia .edu</title><updated>2024-07-15T19:15:54.883068+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) Recurrent #NeuralNetwork for signal processing trained by a new second order algorithm | Aurelio Uncini - Academia .edu</content><link href="https://qi.tc/qi/120664" rel="alternate" type="text/html"/><published>2024-07-15T19:15:54.883068+02:00</published></entry><entry><id>https://qi.tc/qi/120663</id><title>( PDF) Gradient calculations for dynamic recurrent #NeuralNetwork : a survey | Barak Pearlmutter - Academia .edu</title><updated>2024-07-15T19:15:55.053752+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>( PDF) Gradient calculations for dynamic recurrent #NeuralNetwork : a survey | Barak Pearlmutter - Academia .edu</content><link href="https://qi.tc/qi/120663" rel="alternate" type="text/html"/><published>2024-07-15T19:15:55.053752+02:00</published></entry><entry><id>https://qi.tc/qi/120670</id><title>HISTORIAE , History of Socio-Cultural Transformation as Linguistic #DataScience . A Humanities Use Case — @KingsCollegeLon</title><updated>2024-07-15T21:02:47.958646+02:00</updated><author><name>Saqib Ali</name><email>docbook.xml@gmail.com</email></author><content>HISTORIAE , History of Socio-Cultural Transformation as Linguistic #DataScience . A Humanities Use Case — @KingsCollegeLon</content><link href="https://qi.tc/qi/120670" rel="alternate" type="text/html"/><published>2024-07-15T21:02:47.958646+02:00</published></entry></feed>